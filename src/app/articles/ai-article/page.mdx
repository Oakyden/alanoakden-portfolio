import { ArticleLayout } from '@/components/ArticleLayout'

export const article = {
  author: 'Alan Oakden',
  date: '2022-04-14',
  title: 'ğŸš¨ Is AI already moving faster than humanity can handle? ğŸ¤”',
  description:
    'Some musings about the fallout between Sam Altman and OpenAI.',
}

export const metadata = {
  title: article.title,
  description: article.description,
}

export default (props) => <ArticleLayout article={article} {...props} />

## ğŸš¨ Is AI already moving faster than humanity can handle? ğŸ¤”

This morning I watched an interview with Satya Nadella, MD of Microsoft: [Watch here](https://lnkd.in/eP8WvBUn)

For those that have been living under a rock, on Friday OpenAI fired their CEO **Sam Altman**. This caught OpenAIâ€™s investors (including Microsoft themselves) and some of OpenAIâ€™s co-founders by surprise. Rumours and memes spread about what could have happened, but this was not a simple work disagreement â€” it was clear there was a fundamental split in how fast and far OpenAI should be pushing the envelope and releasing capabilities.

At **6:20** in the interview, Satya is asked:

> *"Are you now more concerned than ever about AI safety given how we've seen how fragile these institutions are?"*

Despite how PC Satya was in his answer, it was enough to spell out the issue at hand and how serious this is getting.

---

### ğŸ¤– AI can provide:

- âœ… Everyone in the world with a medical professional  
- âœ… A top-class tutor regardless of the money available  
- âœ… A rural farmer in India having more agency thanks to technology developed in the west of the US days earlier  

---

### âš ï¸ But harms that are happening right now include:

- âŒ Election interference  
- âŒ Deep fakes  
- âŒ Bias fed into learning models (and in turn, public opinion)  
- âŒ Bioterrorism  

---

Some of these issues are even bigger than those seen in world politics right now, and they're largely in the hands of a select few in the West Coast of the US.

Over the last few days, OpenAI held discussions to bring Sam Altman back. With no agreement reached, **Altman will now be heading to Microsoft** to lead a new AI research department. Meanwhile, OpenAI has hired a perhaps more conservative CEO in **Emmett Shear**, who has claimed that his **p(doom)** â€” the probability that AI poses an existential threat to humanity â€” is *between 5% and 50%*.

Edit - Altman has since returned to Open AI ğŸ‘€

---

### ğŸ‘€ I think we should all keep a keen eye on what's coming

We must ensure that we harness AI's capabilities for business and the improvement of society, while also keeping the following in mind:

- What would we do if our enemies were to get their hands on this technology or get ahead in this field?  
- How do we democratise learning models and the influence AI can have?  
- In a world where administration, haulage, travel, data analysis, tutoring, medical research, etc. will be automated and sped up 100x â€” **how will society adapt to a 50%+ unemployment rate?**
